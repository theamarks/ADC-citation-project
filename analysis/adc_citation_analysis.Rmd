---
title: "Arctic Data Center Dataset Citation Analysis"
author: "Althea Marks"
date: '2022-05-24'
output: 
  html_document:
    theme: spacelab
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(jsonlite)
library(tidyr)
library(dplyr)
library(dataone)
library(job)
#library(scythe)
#library(purrr)


# install development version of scythe package with added xdd library
devtools::install_github("dataoneorg/scythe@develop")
```

### Purpose: 
Run ADC DOIs through `scythe` & compare to known DataONE metrics citations. Known ADC citations have mixed origins including DataCite, pervious `scythe` runs, and mannual additions via the ADC UI. 

### Methods Overview:

1) Gather existing/known ADC dataset citations picked up by the automated DataONE metrics API
2) Get a list of all ADC dataset DOIs
3) Run all ADC dataset DOIs through `scythe` libraries
4) Compare citations from `scythe` to DataONE metrics

### Analysis:

#### 1. Retrieve all ADC citations with GET API request with the following request body

metrics service production endpoint: https://logproc-stage-ucsb-1.test.dataone.org/metrics

```{r get_request_citations, eval=FALSE}
{
  "metricsPage":{
    "total":0,
    "start":0,
    "count":0
  },
  "metrics":["citations"],
  "filterBy":[{
    "filterType":"repository",
    "values":["urn:node:ARCTIC"],
    "interpretAs":"list"
  },
  {
    "filterType":"month",
    "values":["01/01/2012",
              "05/24/2022"],
    "interpretAs":"range"
  }],
  "groupBy":["month"]
}
```

Example request:

```{r example_request, eval=FALSE}
https://logproc-stage-ucsb-1.test.dataone.org/metrics?metricsRequest={%22metricsPage%22:{%22total%22:0,%22start%22:0,%22count%22:0},%22metrics%22:[%22citations%22],%22filterBy%22:[{%22filterType%22:%22repository%22,%22values%22:[%22urn:node:ARCTIC%22],%22interpretAs%22:%22list%22},{%22filterType%22:%22month%22,%22values%22:[%2201/01/2012%22,%2205/24/2022%22],%22interpretAs%22:%22range%22}],%22groupBy%22:[%22month%22]
}
```

Function to retrieve dataset citations generated by DataOne metrics service (from Jeanette Clark):

```{r adc_metrics_citations_function}

metrics_citations <- function(from = as.POSIXct("2010-01-01"), to = as.POSIXct(Sys.Date())){

    from <- as.Date(from); to <- as.Date(to)
    from_q <- paste(stringr::str_pad(lubridate::month(from), 2, side = "left", pad = "0"),
                    stringr::str_pad(lubridate::day(from), 2, side = "left", pad = "0"),
                    stringr::str_pad(lubridate::year(from), 2, side = "left", pad = "0"),
                    sep = "/")

    to_q <- paste(stringr::str_pad(lubridate::month(to), 2, side = "left", pad = "0"),
                  stringr::str_pad(lubridate::day(to), 2, side = "left", pad = "0"),
                  stringr::str_pad(lubridate::year(to), 2, side = "left", pad = "0"),
                  sep = "/")

    d <- jsonlite::fromJSON(paste0('https://logproc-stage-ucsb-1.test.dataone.org/metrics?q={%22metricsPage%22:{%22total%22:0,%22start%22:0,%22count%22:0},%22metrics%22:[%22citations%22],%22filterBy%22:[{%22filterType%22:%22repository%22,%22values%22:[%22urn:node:ARCTIC%22],%22interpretAs%22:%22list%22},{%22filterType%22:%22month%22,%22values%22:[%22', from_q,'%22,%22', to_q, '%22],%22interpretAs%22:%22range%22}],%22groupBy%22:[%22month%22]}'))

    output_json <- d$resultDetails$citations # pulls citation info
    output_df <- as.data.frame(do.call(rbind, output_json), row.names = FALSE) # binds nested cit info into dataframe
   # output_clean <- rownames_to_column(output_df, var = "citation_id") # converts row names to column
    return(output_df)
}
```


```{r adc_citations}
# Run ADC API Get call, unnest target_id results to individual columns
cit_2022 <- metrics_citations()

cit_2022 <- tidyr::unnest(cit_2022,
                          cols = c(target_id, source_id, source_url,
                                   link_publication_date, origin, title,
                                   publisher, journal, volume, page, year_of_publishing))

```

#### 2. Get all ADC DOIs from SOLR query

DataOne metrics API can only provide data package DOIs with citations, and can not provide a comprehensive list of all data package DOIs contained within the ADC. To search through all the repository metadata we query the DataONE search index (Apache SOLR search engine). SOLR is the same underlying mechanism that DataONE uses in the online tool and can create complex logical query conditions.

```{r SOLR_query}
# complete list of searchable values
#getQueryEngineDescription(cn, "solr")

# set coordinationg node
cn <- dataone::CNode("PROD")

# point to specific member node
mn <- dataone::getMNode(cn, "urn:node:ARCTIC")

# set up Solr query parameters
queryParamList <- list(q="id:doi*", 
                       fl="id,title,dateUploaded,datasource",
                       start ="0",
                       rows = "100000")
# use `q = "identifier:doi* AND (*:* NOT obsoletedBy:*)"` to only include current versions of data packages 

# send query to Solr, return results as dataframe
result <- dataone::query(mn, solrQuery=queryParamList, as="data.frame", parse=FALSE)
```

#### 3. Run all ADC dataset DOIs through `scythe` libraries

```{r All_ADC_DOIs}
# create vector of all ADC DOIs from solr query `result`
adc_all_dois <- c(result$id)
```

Run each library search in parallel in separate background jobs to keep console available to work with. This will take a long time because of the number of DOIs. By default the `job::job()` imports the global environment into the background job.

**Important Note** `scythe::scythe_set_key()` is a wrapper for the `key_ring` package. An interactive password prompt is required to access the API keys stored in `key_ring`. This *does not work* within a background job environment; your keyring needs to be temporarily unlocked with `keyring::keyring_unlock("scythe", "your password")` replace `password` with your actual keyring password. Be careful not to save, commit, or push your personal keyring password.

```{r citation_searches_background_jobs, eval=FALSE}

# Run each source/library search in a separate background job. Running a for loop will return incomplete results if API query fails, which is better than loosing all progress because of a single error. 

key <- "password"

# Scopus
citations_scopus <- data.frame()

job::job({
  for (i in seq_along(adc_all_dois[1:200])) {
    # access API keys within background job
    keyring::keyring_unlock("scythe", key)
    # suppress errors and continue loop iteration
    try({
      # search for single DOI in source
      citation <- scythe::citation_search(adc_all_dois[1:200][i], "scopus")
      # bind single results together in single data frame
      citations_scopus <- rbind(citations_scopus, citation)
    }, silent = TRUE)
  }
}, title = paste0("scopus citation search ", Sys.time()))

#### tryCatch that produces NAs
# Springer
citations_springer <- data.frame()

job::job({
  for (i in seq_along(adc_all_dois[1:200])){
    keyring::keyring_unlock("scythe", key)
    result <- tryCatch(
      citation <- scythe::citation_search(adc_all_dois[1:200][i], "springer"), 
      error = function(err) NA)
    citations_springer <- rbind(citations_springer, result)
  }
}, title = paste0("springer citation search ", Sys.time()))

# PLOS
citations_plos <- data.frame()

job::job({
  for (i in seq_along(adc_all_dois[1:200])){
  keyring::keyring_unlock("scythe", key)
  citation <- scythe::citation_search(adc_all_dois[1:200][i], "plos")
  citations_plos <- rbind(citations_plos, citation)
  }
}, title = paste0("plos citation search ", Sys.time()))

# xdd
citations_xdd <- data.frame()

job::job({
  for (i in seq_along(adc_all_dois[1:200])){
  keyring::keyring_unlock("scythe", key)
  citation <- scythe::citation_search(adc_all_dois[1:200][i], "xdd")
  citations_xdd <- rbind(citations_xdd, citation)
  }
}, title = paste0("xdd citation search ", Sys.time()))


```

```{r save_results, eval = F}
# function to write api search results to csv within Rproject
# built in check for result files

write_api_results <- function(lib){
  for(i in seq_along(lib)){
    if(exists(paste0("adc_", lib[i]))){ # this needs work doesn't match format of "adc_plos_1"
    eval(parse(text = paste('write.csv(adc_', lib[i], ', file = "./doi_results_', 
                            lib[i] ,"_", Sys.Date(),'.csv")', sep = "")))
    print(paste0(lib[i], " results saved"))
  } else{
    print(paste0(lib[i], " results NOT found"))
  }
  }
}

purrr::map(libraries, write_api_results)

```

[Root of ADC discipline semantics annotations](https://bioportal.bioontology.org/ontologies/ADCAD/?p=classes&conceptid=root) Classes/ID is where to look for query specifics.
"Hereâ€™s an example SOLR query that looks for two of those disciplines: `https://cn.dataone.org/cn/v2/query/solr/?q=sem_annotation:*ADCAD_00077+OR+sem_annotation:*ADCAD_00005&fl=identifier,formatId,sem_annotation`" - Matt 
Need to list every single SS ID in query list, not set up to query umbrella SS ID just yet
