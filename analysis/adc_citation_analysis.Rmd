---
title: "Arctic Data Center Dataset Citation Analysis"
author: "Althea Marks"
date: '2022-05-24'
output: 
  html_document:
    theme: spacelab
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(jsonlite)
library(tidyr)
library(dplyr)
library(dataone)
library(job)
#library(scythe)
library(purrr)


# install development version of scythe package with added xdd library
devtools::install_github("dataoneorg/scythe@develop")
```

### Purpose: 
Run ADC DOIs through `scythe` & compare to known DataONE metrics citations

### Methods Overview:

1) Gather existing/known ADC dataset citations picked up by the automated DataONE metrics API
2) Get a list of all ADC dataset DOIs
3) Run all ADC dataset DOIs through `scythe` libraries
4) Compare citations from `scythe` to DataONE metrics

### Analysis:

#### 1. Retrieve all ADC citations with GET API request with the following request body

metrics service production endpoint: https://logproc-stage-ucsb-1.test.dataone.org/metrics

```{r get_request_citations, eval=FALSE}
{
  "metricsPage":{
    "total":0,
    "start":0,
    "count":0
  },
  "metrics":["citations"],
  "filterBy":[{
    "filterType":"repository",
    "values":["urn:node:ARCTIC"],
    "interpretAs":"list"
  },
  {
    "filterType":"month",
    "values":["01/01/2012",
              "05/24/2022"],
    "interpretAs":"range"
  }],
  "groupBy":["month"]
}
```

Example request:

```{r example_request, eval=FALSE}
https://logproc-stage-ucsb-1.test.dataone.org/metrics?metricsRequest={%22metricsPage%22:{%22total%22:0,%22start%22:0,%22count%22:0},%22metrics%22:[%22citations%22],%22filterBy%22:[{%22filterType%22:%22repository%22,%22values%22:[%22urn:node:ARCTIC%22],%22interpretAs%22:%22list%22},{%22filterType%22:%22month%22,%22values%22:[%2201/01/2012%22,%2205/24/2022%22],%22interpretAs%22:%22range%22}],%22groupBy%22:[%22month%22]
}
```

Function to retrieve dataset citations generated by DataOne metrics service (from Jeanette Clark):

```{r adc_metrics_citations_function}

metrics_citations <- function(from = as.POSIXct("2010-01-01"), to = as.POSIXct(Sys.Date())){

    from <- as.Date(from); to <- as.Date(to)
    from_q <- paste(stringr::str_pad(lubridate::month(from), 2, side = "left", pad = "0"),
                    stringr::str_pad(lubridate::day(from), 2, side = "left", pad = "0"),
                    stringr::str_pad(lubridate::year(from), 2, side = "left", pad = "0"),
                    sep = "/")

    to_q <- paste(stringr::str_pad(lubridate::month(to), 2, side = "left", pad = "0"),
                  stringr::str_pad(lubridate::day(to), 2, side = "left", pad = "0"),
                  stringr::str_pad(lubridate::year(to), 2, side = "left", pad = "0"),
                  sep = "/")

    d <- jsonlite::fromJSON(paste0('https://logproc-stage-ucsb-1.test.dataone.org/metrics?q={%22metricsPage%22:{%22total%22:0,%22start%22:0,%22count%22:0},%22metrics%22:[%22citations%22],%22filterBy%22:[{%22filterType%22:%22repository%22,%22values%22:[%22urn:node:ARCTIC%22],%22interpretAs%22:%22list%22},{%22filterType%22:%22month%22,%22values%22:[%22', from_q,'%22,%22', to_q, '%22],%22interpretAs%22:%22range%22}],%22groupBy%22:[%22month%22]}'))

    output_json <- d$resultDetails$citations # pulls citation info
    output_df <- as.data.frame(do.call(rbind, output_json), row.names = FALSE) # binds nested cit info into dataframe
   # output_clean <- rownames_to_column(output_df, var = "citation_id") # converts row names to column
    return(output_df)
}
```


```{r adc_citations}
# Run ADC API Get call, unnest target_id results to individual columns
cit_2022 <- metrics_citations()

cit_2022 <- tidyr::unnest(cit_2022,
                          cols = c(target_id, source_id, source_url,
                                   link_publication_date, origin, title,
                                   publisher, journal, volume, page, year_of_publishing))

```

#### 2. Get all ADC DOIs from SOLR query

DataOne metrics API can only provide data package DOIs with citations, and can not provide a comprehensive list of all data package DOIs contained within the ADC. To search through all the repository metadata we query the DataONE search index (Apache SOLR search engine). SOLR is the same underlying mechanism that DataONE uses in the online tool and can create complex logical query conditions.

```{r SOLR_query}
# complete list of searchable values
#getQueryEngineDescription(cn, "solr")

# set coordinationg node
cn <- dataone::CNode("PROD")

# point to specific member node
mn <- dataone::getMNode(cn, "urn:node:ARCTIC")

# set up Solr query parameters
queryParamList <- list(q="id:doi*", 
                       fl="id,title,dateUploaded,datasource",
                       start ="0",
                       rows = "100000")
# use `q = "identifier:doi* AND (*:* NOT obsoletedBy:*)"` to only include current versions of data packages 

# send query to Solr, return results as dataframe
result <- dataone::query(mn, solrQuery=queryParamList, as="data.frame", parse=FALSE)
```

#### 3. Run all ADC dataset DOIs through `scythe` libraries

```{r All_ADC_DOIs}
# create vector of all ADC DOIs from solr query `result`
adc_all_dois <- c(result$id)
```

Run each library search in parallel in separate background jobs to keep console available to work with. This will take a long time because of the number of DOIs. By default the `job::job()` imports the global environment into the background job.

**Important Note** `scythe::scythe_set_key()` is a wrapper for the `key_ring` package. An interactive password prompt is required to access the API keys stored in `key_ring`. This *does not work* within a background job environment; your keyring needs to be temporarily unlocked with `keyring::keyring_unlock("scythe", "your password")` replace `password` with your actual keyring password. Be careful not to save, commit, or push your personal keyring password.

```{r citation_searches_background_jobs, eval=FALSE}

# break up ADC DOI catelog into smaller chunks to make API requests more manageable

libraries <- c("plos", "scopus", "springer", "xdd")

# instead of breaking doi vector into chunks, try looping or apply over each individual doi within adc_all_dois
# will not batch fail, will succeed until failure. 

search_libs_chunk_jobs <- function(lib, dois, key) {
  chunks <- c(seq(0, length(dois), by = 1000), length(dois)) # break up list of DOIs into chunks of
  for (i in seq_along(chunks)) {
    #job::job({
      keyring::keyring_unlock("scythe", key)
    if(exists(paste("adc", lib, i, sep = "_"))){
      
    }
      assign(paste("adc", lib, i, sep = "_"),
             scythe::citation_search(dois[chunks[i]:chunks[i+2]], lib))
    #})
  }
}

job::job({
  adc_plos <- scythe::citation_search_plos(adc_all_dois)},
  title = "plos search"
  )

job::job({
  keyring::keyring_unlock("scythe", "password")
  adc_scopus <- scythe::citation_search_scopus(adc_all_dois[1:1000])},
  title = "scopus search"
  )

job::job({
  keyring::keyring_unlock("scythe", "password")
  adc_springer <- scythe::citation_search_springer(test)},
  title = "springer search"
  )

job::job({
  adc_xdd <- scythe::citation_search_xdd(adc_all_dois)},
  title = "xdd search"
  )

```

```{r save_results, eval = F}
# function to write api search results to csv within Rproject
# built in check for result files

write_api_results <- function(lib){
  for(i in seq_along(lib)){
    if(exists(paste0("adc_", lib[i]))){ # this needs work doesn't match format of "adc_plos_1"
    eval(parse(text = paste('write.csv(adc_', lib[i], ', file = "./doi_results_', 
                            lib[i] ,"_", Sys.Date(),'.csv")', sep = "")))
    print(paste0(lib[i], " results saved"))
  } else{
    print(paste0(lib[i], " results NOT found"))
  }
  }
}

purrr::map(libraries, write_api_results)

```

